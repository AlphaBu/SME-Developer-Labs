<table style="width:100%">
  <tr>
    <th width="100%" colspan="5"><h2>AWS F1 Xilinx Developer Labs</h2></th>
  </tr>
  <tr>
    <td width="20%" align="center"><a href="README.md">Introduction</a></td>
    <td width="20%" align="center"><a href="SETUP.md">1. Connecting to your F1 instance</a></td> 
    <td width="20%" align="center"><a href="FFMPEG_Lab.md">2. Experiencing F1 acceleration</a></td>
    <td width="20%" align="center"><b>3. Developing F1 applications</b></td>
    <td width="20%" align="center"><a href="AVFILTER_Lab.md">4. Creating a custom FFmpeg plugin</td>
    <td width="20%" align="center"><a href="WRAP_UP.md">5. Wrapping-up</td>
  </tr>
</table>
	
---------------------------------------
	
### Developing, profiling and optimizing F1 applications with SDAccel

This tutorial is designed to teach the fundamentals of the SDAccel development environment and programming model. This includes: familiarizing with OpenCL, understanding software and hardware emulation flows, profiling performance and identifying how to optimize host and kernel code. 

The kernel used in this tutorial is a 2D video filter, a function widely used in video processing algorithms such as noise reduction, and image sharpening. 

To simplify this tutorial, a workspace preloaded with the initial project configuration is provided in the lab repository.

Please also note that although the entire tutorial is performed on an F1 instance, only the final step of this tutorial really needs to be run on F1. All the interactive development, profiling and optimization steps would normally be performed on-premise or on a cost-effective AWS EC2 instance such as C4. However, to avoid switching from C4 to F1 instances during this tutorial, all the steps are performed on the F1 instance.

### Starting SDAccel

1.  Open a new terminal by right-clicking anywhere in the Desktop area and selecting **Open Terminal**. 

1.  Source the SDAccel environment  

    ```bash
    cd ~/aws-fpga
    source sdaccel_setup.sh
    source $XILINX_SDX/settings64.sh 
    cd ~
    ```
	*Note: the sdaccel_setup.sh script might generate warning messages, but these can be safely ignored.*


1. Launch the SDAccel GUI and open the predefined workspace containing the Filter2D project: 
    ```bash
    sdx -workspace /home/centos/AWS-F1-Developer-Labs/workspace
    ```
	*Note: a warning message may appear if loading Eclipse takes longer than expected. Click **Wait** to dismiss it.*

	The predefined workspace takes care of the following setup steps:
	* Creating a new project called **Filter2D**
	* Adding the AWS-VU9P-F1 platform to the project and selecting it as the target for this project 
	* Importing the host and kernel source files
	* Setting the name of the FPGA binary container as **binary_container_1**
	* Setting the **Filter2DKernel** function to be a custom hardware function (also referred to as kernel).
	* Mapping the ports of the **Filter2DKernel** function to two different memory interfaces; one for reads and one for writes. 
	* Setting **binary_container_1** to be the first argument passed to the host application when it is executed.	

	Most of this information is displayed in the **SDX Project Settings** window which is prominently displayed in the center of the GUI. It indicates the project name (**Filter2D**), the selected platform (**AWS-VU9-F1**) and the FPGA binary container (**binary_container_1**) with the hardware function (**Filter2DKernel**).  
 
    ![](./images/filter2d_lab/SDxWindows.PNG)

1. Familiarize yourself with the different sections of the GUI layout:
    * The **main menu** bar is located on the top. This menu bar allows direct access to all general project setup and GUI window management tasks. As most tasks are performed through the different setup windows, the main menu is mostly used to recover from accidently closed windows or to access the tool help.
    * Directly below the main menu bar is the **SDAccel toolbar**.  This provides access to the most common tasks in a project. From left to right, these are: File Management functions (new, save, save all), Configuration Management, Build, Build All, Start Debug, and Run. Most buttons have a default behavior as well as pulldowns.
    * The **Project Explorer** window occupies the top left hand side of the GUI. This window is used to manage and navigate through project files. In the expanded **src** folder you should be able to see the source files of the project. 
    * In the middle is the **SDx Project Settings** window. This window is intended for project management and presents the key aspects of an SDx Project. 
    * The **Outline** viewer on the right hand side is used for file navigation. The content of the outline varies depending on the file currently selected in the main window.
    * In the bottom left section is the **Reports window**. This allows easy access to all reports generated by SDAccel. 
    * The remaining windows along the bottom of the main window accommodate the various consoles and terminals which contain output information relating to individual SDAccel executables. Typical output examples are compilation errors or the tool output when running.  

### Overview of the source code used in this example

1. Expand the **src** directory in the **Project Explorer**. 
The project is comprised of two directories:
	* **host** contains the code for the host application running on the CPU.
	* **kernel** contains the code for the kernel (custom accelerator) running on the FPGA.

1. Expand the **host** directory in the **Project Explorer**. 
The host code is comprised of the following files:
	* **host.cpp** contains the main application code.
	* **filter2d.cpp** contains the code for the filter function running on the CPU.
	* **xclbin_helper.cpp and .h** contains helper code for downloading accelerators to the FPGA.
	* **cmdlineparser.cpp and .h** contains the code for parsing command line arguments.
	* **logger.cpp and .h** contains code for logging information.

1. Expand the **kernel** directory in the **Project Explorer**. 
The kernel code is comprised of the following files:
	* **filter2d.cpp** contains the code for the filter function running on the FPGA.
	* **axi2stream.cpp and .h** contains the code for efficiently reading from and writing to memory.
	* **window_2d.h and hls_video_mem.h** contains the code for handling video line buffers and pixel windows.

1. Now open the **filter2d.cpp** file under **src/kernel**.

1. Locate the **Outline** viewer located on the right side of the GUI. 
	* This view provides a convenient way of looking-up and navigating the code hierarchy. 
	* Each green dot in the **Outline** viewer corresponds to a function in the selected source file. 

    ![](./images/filter2d_lab/OutlineKrnl.PNG)

1. In the **Outline** viewer, click **Filter2DKernel** to look-up this function. 
	* The **Filter2DKernel** function is the top-level of the filter kernel implemented in the custom hardware accelerator. Interface properties for the accelerator are specified in this function. 
	* This computationally heavy function can be highly parallelized on the FPGA, providing significant acceleration over a CPU-based implementation.
	* The kernel encapsulates the three main functions of the accelerator: **AXIBursts2PixelStream**, **Filter2D**, and **PixelStream2AXIBursts**.
	* The **AXIBursts2PixelStream** function reads from global memory values sent by the host application and streams them to the **Filter2D** function.
	* The **Filter2D** function receives the pixel data and performs the actual filter computations, and streams the results back out.
	* The **PixelStream2AXIBursts** function receives the streaming results from the **Filter2D** function and writes them back to global memory for the host application.
	* Observe that the three functions are communicating using `hls::streams` objects. These objects model a FIFO-based communication scheme. This is the recommended coding style which should be used whenever possible to exhibit streaming behavior and allow DATAFLOW optimization.
		- The DATAFLOW optimization allows each of the subsequent functions to execute as independent processes. 
		- This results in overlapping and pipelined execution of the read, execute and write functions instead of sequential execution.
		- The FIFO channels between the different processes do not need to buffer the complete dataset anymore but can directly stream the data to the next block. 
	* Note that the **Filter2D** kernel processes only a single plane. At compile time, we can choose to have 1 or many kernels in the FPGA. 
		- In case there is only 1 kernel in the FPGA, a planar formatted YUV 4:4:4 image will have its luma and chroma planes procesed sequentially. 
		- In case there are 3 kernels in the FPGA, the luma and both chroma planes can be processed in parallel, therefore having a higher performance, at the cost of more FPGA resources. We will get back to this later in the lab.

1. Using the **Outline** viewer, quickly look-up and inspect the other important function of the accelerator:
	* The **Filter2D** function is the heart of the custom hardware accelerator that peforms the filter computations.
	* It uses the **Window2D** class that provides an abstraction for getting a two-dimensial pixel window, then performs a simple convolution of the pixels in this window with a programmable filter.
	* Note that one iteration of the **for x** loop will execution in one clock cycle. The resulting hardware will therefore use 15*15=225 multipliers.
	
1. Now open the **host.cpp** file (from the **src/host** folder of the **Project Explorer** view).  

1. Again, use the **Outline** viewer to quickly look-up and inspect the two main functions of the host application:
	* The **main** function of the C++ program initializes the test vectors, sets-up OpenCL, runs the reference model, runs the hardware accelerator, releases the OpenCL resources, and compares the results of the reference Filter2D model with the accelerator implementation.
	* The **Filter2DDispatcher** class takes care of calling the hardware accelerated Filter2DKernel. This class uses the OpenCL API calls to communicate with the FPGA and this is covered in greater detail later in this tutorial.

1. Go to line 90 of the **host.cpp** file by pressing **Ctrl+L** and entering **90**. 

	Locate the call to the **load_xclbin_file** function. This function is where the OpenCL environment is setup in the host application. This section is typical of most SDAccel application and will look very familiar to developers with prior OpenCL experience. This body of code can often be reused as-is from project to project. 

	To setup the OpenCL environment, the following API calls are made:

	* **clGetPlatformIDs**: This function queries the system to identify the different OpenCL platforms. It is called twice as it first extracts the number of platforms before extracting the actual supported platforms.
	* **clGetPlatformInfo**: Get specific information about the OpenCL platform, such as vendor name and platform name.
	* **clGetDeviceIDs**: Obtain list of devices available on a platform.
	* **clCreateContext**: Creates an OpenCL context, which manages the runtime objects.
	* **clGetDeviceInfo**: Get information about an OpenCL device like the device name.
	* **clCreateProgramWithBinary**: Creates a program object for a context, and loads specified binary data into the program object. The actual program is obtained before this call through the load_file_to memory function.

	Note: all objects accessed through a **clCreate...** function call are to be released before terminating the program by calling **clRelease...**. This avoids memory leakage and clears the locks on the device.

1. Now go back to the **host.cpp** file, and take a look at the **Filter2DDispatcher** class. 

	The **Filter2DDispatcher** class takes care of calling the hardware accelerated Filter2DKernel. This class uses the following OpenCL API calls to communicate with the FPGA: 
	* **clCreateKernel**: Creates a kernel object.
	* **clCreateCommandQueue**: Create a command-queue on a specific device.
	* **clCreateBuffer**: Creates a memory buffer.
	* **clEnqueueMigrateMemObjects**: Migrates a set of memory objects to the OpenCL device associated or to the host.
	* **clSetKernelArg**: Sets a kernel argument.
	* **clEnqueueTask**: Enqueues a command to execute a kernel on a device.
	* **clSetEventCallback**: Registers a user callback function for a specific command execution status.

	All of the above API functions are documented by the [Khronos Group](https://www.khronos.org), the maintainers of OpenCL, the open standard for parallel programming of heterogeneous systems

### Running the Emulation Flows

SDAccel provides two emulation flows which allow testing the application before deploying on the F1 instance. The flows are referred to as software emulation (or Emulation-CPU) and hardware emulation (or Emulation-HW), respectively.
* Software emulation is used to identify syntax issues and verify the functional behavior of the application.
* Hardware emulation is used to get performance estimates for the accelerated application.

SDAccel uses Makefiles to perform incremental compilation of the project. This means that unless file changes require the recompilation of the host code or of the kernel code, no compilation is performed.

1. Return to the **SDx Project Settings** by clicking on **project.sdx** in the **Project Explorer** window (left side of the GUI).

1. In the upper right corner of the **SDx Project Settings** window, the **Active build configuration** is shown. Ensure that **Emulation-CPU** is selected.

1. Click the **Run** button ![](./images/Filter2D_lab/RunButton.PNG) to run software emulation.

	* In software emulation, both the host code and the kernel code are compiled to run on the x86 processor. 
	* This allows iterative algorithm refinement through fast build and run loops.
	* The **Console** provides the detailed build log during the compilation of the kernel and the host code. It then displays the standard output produced by the application during the actual emulation run.  
	* The software emulation is complete when the following messages are displayed at the bottom of the **Console**:

	```
	TEST PASSED
	RUN COMPLETE
	```	
	
1. In the **SDx Project Settings**, change the **Active build configuration** to **Emulation-HW**.

1. Click the **Run** button again or click **Ctrl+F11** to build and run the hardware emulation flow.

	* In hardware emulation, the host code is compiled to run on the x86 processor and the kernel code is compiled into a hardware model (known as RTL or Register Transfer Level) which is run in a special simulator.
	* The build and run cycle takes longer because the kernel code is compiled into a detailed hardware model which is slower to simulate.
	* The more detailed hardware simulation allows more accurate reporting of kernel and system performance.
	* This flow is also useful for testing the functionality of the logic that will go in the FPGA.
	* The hardware emulation is complete when the following messages are displayed at the bottom of the **Console**:
	
	```
	TEST PASSED
	RUN COMPLETE
	```

### Analyzing the Reports  

This section covers how to locate and read the various reports generated by the emulation runs. The goal of the section is to understand the analysis reports of SDAccel before utilizing them in the next section.  

1. Locate the **Reports** window in the bottom-left corner of the GUI. 
	* This window displays a tree layout of folders and reports for all runs and open projects. 
	* The top level shows the **Filter2D** project for which we have executed two runs: **Emulation-CPU** and **Emulation-HW**.

    ![](./images/filter2d_lab/Reports.PNG)

1. Look into the **Emulation-CPU** folder. 
	* The **Filter2D-Default** run configuration folder contains the **Profile Summary** and **Application Timeline** report generated during the software emulation run.

1. Look into the **Emulation-HW** folder.
	* The **Filter2D-Default** run configuration folder contains the **Profile Summary** and **Application Timeline** report generated during the hardware emulation run.
	* The **binary_container_1** folder contains the **HLS Report** from the compilation of the C++ kernel into the detailed hardware model (RTL). This compilation step is often referred to as High Level Synthesis or HLS.

1. Open the **Profile Summary** report from the **Emulation-CPU** run. 

    ![](./images/filter2d_lab/SWProfile.PNG) 

    _Note: in software emulation, profiling numbers may vary due to CPU and system loading._
    
    This report provides data related to how the application runs. Notice that the report has four tabs at the top: **Top Operations**, **Kernels & Compute Units**, **Data Transfers**, and **OpenCL APIs**. 
    
    Click through and inspect each of the tabs:

    * **Top Operations**: Shows all the major top operations of memory transfer between the host and kernel to global memory, and kernel execution. This allows you to identify throughput bottlenecks when transferring data. Efficient transfer of data to the kernel/host allows for faster execution times.
    
    * **Kernels & Compute Units**: Shows the number of times the kernel was executed. Includes the total, minimum, average, and maximum run times. If the design has multiple compute units, it will show each compute unit’s utilization. When accelerating an algorithm, the faster the kernel executes, the higher the throughput which can be achieved. It is best to optimize the kernel to be as fast as it can be with the data it requires.
    
    * **Data Transfers**: This tab has no bearing in software emulation as no actual data transfers are emulated across the host to the platform. In hardware emulation, this shows the throughput and bandwidth of the read/writes to the global memory that the host and kernel share.
    
    * **OpenCL APIs**: Shows all the OpenCL API command executions, how many time each was executed, and how long they take to execute.

1. Open the **Application Timeline** report from the **Emulation-CPU** run. 

    ![](./images/filter2d_lab/SWTimeline.PNG)	
       
    The **Application Timeline** collects and displays host and device events on a common timeline to help you understand and visualize the overall health and performance of your systems. These events include OpenCL API calls from the host code: when they happen and how long each of them takes.
    
1. Open the **Profile Summary** from the **Emulation-HW** run.

    ![](./images/filter2d_lab/HWProfile.PNG)

1. Locate the **Profile Rule Checks** section at the bottom of the **Profile Summary** 
    - **Profile Rule Checks** (PRCs) interpret profiling results and suggest areas for performance improvements.
    - PRCs compare profiling results to threshold values. If a check does not meet the threshold value, the right hand column provides guidance on how to improve performance.
    - PRCs work for both hardware emulation and system runs on the FPGA.

1. Click on the **Kernels & Compute Units** tab of the **Profile Summary** report, locate and note the following numbers:

    - Kernel Total Time (ms):

    This number will serve as reference point to compare against after optimization.    
    
1. Open the **HLS Report** from the **Emulation-HW** run.

    - The **HLS Report** is explains the results of compiling the kernel into hardware. It contains many details (including clocking, resources or device utilization) about the performance and logic usage of the custom-generated hardware logic. These details provide many insights to guide the kernel optimization process.    
    
    - For the needs of this tutorial, we will focus on the **Performance Estimates** section located in the middle of the main **Synthesis** tab. This section provides information on the latency of the kernel, as well as loop implementation details.  

1. In the left pane of the **HLS Report**, select the **Filter2DKernel** function.

    ![](./images/filter2d_lab/LatencyKrnlIdctDataflow3.PNG)

1. In the **Performance Estimates** section, locate the **Latency (clock cycles) > Summary** table and note the following numbers:

    - Latency (min/max):
    - Interval (min/max):

	The numbers will serve as a baseline for comparison against optimized versions of the kernel.

1. Right under the table, locate and expand the **Detail > Instance** sub-section.

	* Note that the 3 sub-functions read, execute and write have roughly the same latency and that their sum total is equivalent to the total Interval reported in the **Summary** table. 
	* This indicates that the three sub-functions are executing sequentially, hinting to an optimization opportunity.

1. Close all the reports by clicking the **X** in each of the report tabs.
 

### Optimization   

The previous section explained the SDAccel performance analysis capabilities. The next stage is to utilize these analysis capabilities to drive and measure code optimizations. This tutorial illustrates the DATAFLOW optimization for the kernel and software pipelining for the host application.


### Kernel Optimization  

TBD, only thing I can propose is for example to get rid of the / in the filter and change it into a shift, not sure how much of a difference that will make.
If we had more time, I would propose we change the kernel into a kernel that processes multiple pixels in parallel, but this has consequences to quite a bit of code.


### Host Code Optimization

1. Open **host.cpp** file (from the **Project Explorer** window).  

1. Using the **Outline** viewer, navigate to the **runFPGA** function.

	For each block of 8x8 values, the **runFPGA** function writes data to the FPGA, runs the kernel, and reads results back. 
	
	Communication with the FPGA is handled by OpenCL API calls made within the cu.write, cu.run and cu.read functions.
	- **clEnqueueMigrateMemObjects** schedules the transfer of data to or from the FPGA.
	- **clEnqueueTask** schedules the executing of the kernel.

	These OpenCL functions use events to signal their completion and synchronize execution.
	
1. Open the **Application Timeline** of the **Emulation-HW** run.  

	The green segments at the bottom indicate when the Filter2D kernel is running.

1. Notice that there are gaps between each of the green segments.

1. Zoom in by performing a **Left mouse drag** across one of these gaps to get a more detailed view.  

    ![](./images/filter2d_lab/ZoomApplicationTimeline.PNG)

    - The two green segments correspond to two consecutive invocations of the Filter2D kernel. 
    - The gap between the two segments is indicative of idle time between these two invocations. 
    - The **Data Transfer** section of the timeline shows that **Read** and **Write** operations are happening when the kernel is idle. 
    - The **Read** operation is to retrieve the results from the execution which just finished and the **Write** operation is to send inputs for the next execution. 
    - This represents a sequential execution flow of each iteration.  
    
1. Close the **Application Timeline**.    
	
1. In the **idct.cpp** file, go to the **oclDct::write** function.

	- Observe that on line 353, the function synchronizes on the **outEvVec** event through a call to **clWaitForEvents**. 
	- This event is generated by the completion of the **clEnqueueMigrateMemObjects** call in the **oclDct::read** function (line 429).
	- Effectively the next execution of the **oclDct::write** function is gated by the completion of the previous **oclDct::read** function, resulting in the sequential behavior observed in the **Application Timeline**. 
	
	
1. Use the **Outline** viewer to locate the definition of the **NUM_SCHED** macro in the **idct.cpp** file.
	
	- This macro defines the depth of the event queue.
	- The value of **1** explains the observed behavior: new tasks (write, run, read) are only enqueued when the previous has completed effectively synchronizing each loop iteration. 
	- By increasing the value of the **NUM_SCHED** macro, we increase the depth of the event queue and enable more blocks to be enqueued for processing. This will result in the write, run and read tasks to overlap and allow the kernel to execute continuously. 
	- This technique is called **software pipelining**. 
	
1. Modify line 213 to increase the value of **NUM_SCHED** to 6 as follows:
	```C
	#define NUM_SCHED 6
	```
1. Save the file (**Ctrl-S**) and rerun hardware emulation by clicking the run button ![](./images/filter2d_lab/RunButton.PNG). 

    - Since only the **idct.cpp** file was change, the incremental makefile rebuilds only the host code before running emulation.
    - This results in a much faster iteration loop since it is usually the compilation of the kernel to hardware which takes the most time.
    
1. Once completed, reopen the **Application Timeline** and observe how **software pipelining** enables overlapping of data transfers and kernel execution.

    ![](./images/filter2d_lab/ZoomApplicationTimelineEnd.PNG)
	
	Note: system tasks might slow down communication between the application and the hardware simulation, impacting on the measured performance results. The effect of software pipelining is considerably higher when running on the actual hardware. 

### Building the FPGA binary to execute on F1 

Once the application and kernel code have been optimized, the next step is to create an FPGA binary for execution on the F1 instance. 

Creating the FPGA binary is a two-step process:
* First SDAccel is used to build the Xilinx FPGA binary (.xclbin file).
* Then the AWS **create_sdaccel_afi.sh** script is used to create the AWS FPGA binary (.awsxclbin file) and register a secured and encrypted Amazon FPGA Image (AFI).

The **create_sdaccel_afi.sh** script does the following:
* Starts a background process to create the AFI
* Generates a \<timestamp\>_afi_id.txt which contains the FPGA Image Identifier (or AFI ID) and Global FPGA Image Identifier (or AGFI ID) of the generated AFI
* Creates the *.awsxclbin AWS FPGA binary file which is read by the host application to determine which AFI should be loaded in the FPGA.

These steps would take too long to complete during this tutorial, therefore a precompiled FPGA binary is used to continue this lab and execute on F1.

### Executing on F1 

1. Close the SDAccel GUI and report to the terminal from which you started the tool.

1. Confirm that FPGA binary (.awsxclbin file) is indeed present.

	```bash
	# Go the lab folder
	cd /home/centos/AWS-F1-Developer-Labs/idct
	
	# List contents of the ./xclbin directory to look for the .awsxclbin FPGA binary
	ls -la ./xclbin
	```
	
1. Retrieve the FPGA Image Global Id (agfi) from the \<timestamp\>_afi_id.txt file.
	
	```bash
	more ./xclbin/17_10_25-143305_afi_id.txt
	```	

1. Confirm that the FPGA Image is ready and available using the retrieved Id.

	``` bash
	aws ec2 describe-fpga-images --filters Name=fpga-image-global-id,Values=agfi-0b8ba55a71fd665b9
	```
   
   The output of this command should contain:

    ``` json
    ...
    "State": {
        "Code": "available"
    },
    ...
    ```	
	
1. Copy the host application executable built in the SDAccel workspace to the local directory and execute the accelerated application on F1 using the FPGA binary.

    ``` shell
    # Copy the host application executable
    cp /home/centos/AWS-F1-Developer-Labs/workspace/Filter2D/Emulation-HW/Filter2D.exe .
   
    sudo sh
    # Source the SDAccel runtime environment
    source /opt/Xilinx/SDx/2017.1.rte/setup.sh
    # Execute the host application with the .awsxclbin FPGA binary
    ./Filter2D.exe ./xclbin/binary_container_1.awsxclbin
    ```

    Note the performance difference between the Filter2D running on the CPU and the Filter2D running in the FPGA.

	TBD need to add on to this to show how to run 1 vs 3 kernels, then explain performance numbers based on 1 pixel per clock, kernel clock, image size, etc.
	
### Summary  

In this lab, you learned:
* Key features of the SDAccel development environment
* Important OpenCL API calls to communicate between the host and the FPGA
* The differences between the software and hardware emulation flows and how to run them
* How to read the various reports generated by SDAccel
* How to use pragmas to increase kernel performance
* How to use software pipelining to increase system performance
 
---------------------------------------

<p align="center"><b>
Start the next module: <a href="AVFILTER_Lab.md">4. Creating a custom FFmpeg plugin</a>
</b></p>  
